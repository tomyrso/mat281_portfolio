{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomyrso/mat281_portfolio/blob/master/docs/homeworks/hw_02_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slxlDW74HRgS"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fralfaro/MAT281_2024/blob/main/docs/homeworks/hw_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "\n",
        "# MAT281 - Tarea N°02\n",
        "\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "1.- Completa tus datos personales (nombre y rol USM) en siguiente celda.\n",
        "\n",
        "\n",
        "* __Nombre__: Tomas Rojas\n",
        "\n",
        "* __Rol__: 202110533-6\n",
        "\n",
        "2.- Debes _subir_ este archivo con tus cambios a tu repositorio personal del curso, incluyendo datos, imágenes, scripts, etc.\n",
        "\n",
        "3.- Se evaluará:\n",
        "   - Soluciones\n",
        "   - Código\n",
        "   - Al presionar  `Kernel -> Restart Kernel and Run All Cells` deben ejecutarse todas las celdas sin error.\n",
        "   \n",
        "4.- Esta Tarea debe ser entregada en **Dos Jupyter Notebooks Distinto**.\n",
        "   * **Ejemplo**: `hw_02_part_01.ipynb`, `hw_02_part_02.ipynb`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYvbWoaGHRgX"
      },
      "source": [
        "## II.- Titanic - Machine Learning from Disaster\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/8c/ef/e7/8cefe799c4d5d2ad4ad7f6524d3838f4.png\" width = \"400\" align=\"center\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-obfDv25HRgX"
      },
      "source": [
        "El desafío **Titanic - Machine Learning from Disaster** en [Kaggle](https://www.kaggle.com/competitions/titanic/overview/description) invita a predecir qué pasajeros sobrevivieron al naufragio del Titanic mediante un modelo de machine learning. Utiliza datos reales de los pasajeros, como su nombre, edad, género y clase socioeconómica, para explorar patrones de supervivencia y construir un modelo predictivo. Este es uno de los desafíos más populares de Kaggle y un excelente punto de partida para aprender sobre machine learning y análisis de datos.\n",
        "\n",
        "### Pasos para participar:\n",
        "\n",
        "1. **Unirse a la competencia**:\n",
        "   - [Crea una cuenta o inicia sesión en Kaggle](https://www.kaggle.com/account/login?returnUrl=%2Fc%2Ftitanic) y acepta las reglas para acceder a los datos de la competencia.\n",
        "   \n",
        "2. **Descargar y explorar los datos**:\n",
        "   - Descarga los archivos `train.csv` y `test.csv` desde la [página de datos](https://www.kaggle.com/competitions/titanic/data).\n",
        "   - `train.csv` contiene información de 891 pasajeros, incluyendo si sobrevivieron o no (columna `Survived`). En `test.csv`, se oculta esta columna para que tu modelo prediga la supervivencia de 418 pasajeros adicionales.\n",
        "\n",
        "3. **Desarrollar el modelo**:\n",
        "   - Usa `train.csv` para explorar y descubrir patrones, luego entrena un modelo de machine learning que pueda predecir la supervivencia en `test.csv`. Un recurso útil para aprender es el [tutorial de Alexis Cook](https://www.kaggle.com/alexisbcook/titanic-tutorial), que explica paso a paso cómo hacer tu primera predicción.\n",
        "   - Puedes explorar notebooks de otros participantes para inspiración y técnicas avanzadas en la [sección de notebooks](https://www.kaggle.com/c/titanic/notebooks).\n",
        "\n",
        "4. **Realizar una predicción y enviar tu archivo**:\n",
        "   - El archivo CSV de predicciones debe tener dos columnas: `PassengerId` y `Survived`. Puedes consultar un ejemplo en el archivo `gender_submission.csv` disponible en la [página de datos](https://www.kaggle.com/competitions/titanic/data).\n",
        "   - Sube tu archivo en la sección de envíos y revisa tu puntaje de precisión, que mide el porcentaje de pasajeros que tu modelo predijo correctamente.\n",
        "\n",
        "5. **Revisar el leaderboard y mejorar el modelo**:\n",
        "   - Ve tu posición en el [leaderboard](https://www.kaggle.com/c/titanic/leaderboard) y mejora tu modelo basándote en ideas de los foros o pruebas adicionales.\n",
        "\n",
        "### Ayuda y recursos adicionales:\n",
        "\n",
        "- [Foro de discusión del Titanic](https://www.kaggle.com/c/titanic/discussion): Un espacio donde puedes hacer preguntas y ver consejos de otros participantes.\n",
        "- [Vídeo sobre la jerga de Kaggle](https://www.youtube.com/watch?v=sEJHyuWKd-s) por Dr. Rachael Tatman, para entender mejor los términos comunes en Kaggle.\n",
        "- [Notebooks de la competencia](https://www.kaggle.com/c/titanic/notebooks): Revisa notebooks compartidos para ver cómo otros abordan el desafío.\n",
        "\n",
        "Este desafío es ideal para principiantes en machine learning y permite practicar desde la limpieza de datos hasta el desarrollo y evaluación de modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bNdkva3fHRgX"
      },
      "outputs": [],
      "source": [
        "## base imports ##\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSTGFlZGHoi4",
        "outputId": "6a48b789-3c11-426a-bbd1-17c49e114031"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gender_submission_df = pd.read_csv('/content/drive/MyDrive/content/gender_submission.csv') #este es un ejemplo de submission\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/content/test.csv') #datos a testear\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/content/train.csv') #datos para entrenar"
      ],
      "metadata": {
        "id": "K5QUoHzsHogp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Survived'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "PwUEILA2Hoei",
        "outputId": "c0354057-e98a-47c7-dbb0-1174bffcb6c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived\n",
              "0    549\n",
              "1    342\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Survived</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>342</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_df:')\n",
        "print(train_df.isna().sum())\n",
        "print('\\n')\n",
        "print('test_df:')\n",
        "print(test_df.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sNJ0LJ7HocM",
        "outputId": "6b33136c-5d5e-4fed-f56b-c4cf6bf4e053"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "test_df:\n",
            "PassengerId      0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Has_Cabin'] = train_df[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "test_df['Has_Cabin'] = test_df[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)"
      ],
      "metadata": {
        "id": "epSGhzewHoZ2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = [train_df, test_df]\n",
        "for dataset in full_data:\n",
        "    age_avg = dataset['Age'].mean()\n",
        "    dataset['Age'][np.isnan(dataset['Age'])] = age_avg\n",
        "    dataset['Age'] = dataset['Age'].astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjGOdTgFHoXo",
        "outputId": "b4dcab69-4a99-4b94-b7fe-f45872499ea0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-409d020f6130>:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  dataset['Age'][np.isnan(dataset['Age'])] = age_avg\n",
            "<ipython-input-11-409d020f6130>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset['Age'][np.isnan(dataset['Age'])] = age_avg\n",
            "<ipython-input-11-409d020f6130>:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  dataset['Age'][np.isnan(dataset['Age'])] = age_avg\n",
            "<ipython-input-11-409d020f6130>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset['Age'][np.isnan(dataset['Age'])] = age_avg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in full_data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(train_df['Fare'].mean())"
      ],
      "metadata": {
        "id": "-vLtMKCNHoUW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in full_data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna('S')"
      ],
      "metadata": {
        "id": "_sL54G42HoSP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_elements = ['Cabin']\n",
        "train_df = train_df.drop(drop_elements,axis=1)\n",
        "test_df = test_df.drop(drop_elements,axis=1)"
      ],
      "metadata": {
        "id": "k5nWb0nsHoQA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_df:')\n",
        "print(train_df.isna().sum())\n",
        "print('\\n')\n",
        "print('test_df:')\n",
        "print(test_df.isna().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8fMBIWmIZ6V",
        "outputId": "4c09ebed-feff-4ac6-b842-a1e6aa6d4ff2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df:\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "Has_Cabin      0\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "test_df:\n",
            "PassengerId    0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "Has_Cabin      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Ticket_type'] = train_df['Ticket'].apply(lambda x: x[0:3])\n",
        "train_df['Ticket_type'] = train_df['Ticket_type'].astype('category')\n",
        "train_df['Ticket_type'] = train_df['Ticket_type'].cat.codes\n",
        "\n",
        "test_df['Ticket_type'] = test_df['Ticket'].apply(lambda x: x[0:3])\n",
        "test_df['Ticket_type'] = test_df['Ticket_type'].astype('category')\n",
        "test_df['Ticket_type'] = test_df['Ticket_type'].cat.codes\n",
        "\n",
        "train_df = train_df.drop('Ticket',axis=1)\n",
        "test_df = test_df.drop('Ticket',axis=1)"
      ],
      "metadata": {
        "id": "5af8__ZlIZ3z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Words_Count'] = train_df['Name'].apply(lambda x: len(x.split()))\n",
        "test_df['Words_Count'] = test_df['Name'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "16z84_7rIZ1c"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_title(name):\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # Si el titulo existe, extraer\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "# Agregar la nueva col\n",
        "train_df['Title'] = train_df['Name'].apply(get_title)\n",
        "test_df['Title'] = test_df['Name'].apply(get_title)\n",
        "# Agrupar los titulos raros como \"Rare\"\n",
        "\n",
        "train_df['Title'] = train_df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "train_df['Title'] = train_df['Title'].replace('Mlle', 'Miss')\n",
        "train_df['Title'] = train_df['Title'].replace('Ms', 'Miss')\n",
        "train_df['Title'] = train_df['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "test_df['Title'] = test_df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "test_df['Title'] = test_df['Title'].replace('Mlle', 'Miss')\n",
        "test_df['Title'] = test_df['Title'].replace('Ms', 'Miss')\n",
        "test_df['Title'] = test_df['Title'].replace('Mme', 'Mrs')"
      ],
      "metadata": {
        "id": "hqeRIoiUIZzH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
        "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1"
      ],
      "metadata": {
        "id": "YMfGvWxgIZwx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Sex'] = train_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "test_df['Sex'] = test_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "\n",
        "\n",
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "train_df['Title'] = train_df['Title'].map(title_mapping)\n",
        "train_df['Title'] = train_df['Title'].fillna(0)\n",
        "test_df['Title'] = test_df['Title'].map(title_mapping)\n",
        "test_df['Title'] = test_df['Title'].fillna(0)\n",
        "\n",
        "train_df['Embarked'] = train_df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "test_df['Embarked'] = test_df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)"
      ],
      "metadata": {
        "id": "Xq3zB94JIZuQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_elements = [ 'Name', 'SibSp']\n",
        "train_df = train_df.drop(drop_elements, axis = 1)\n",
        "test_df  = test_df.drop(drop_elements, axis = 1)"
      ],
      "metadata": {
        "id": "XuF6sQtYIZr7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf',C=1000)\n",
        "grad = GradientBoostingClassifier(n_estimators=10000,learning_rate=0.0005,max_depth=3)\n",
        "X_train,X_test,y_train,y_test = train_test_split(train_df.drop(['PassengerId','Survived'],axis=1),train_df['Survived'],test_size=0.1)\n",
        "svm.fit(X_train,y_train)\n",
        "print('train score:',svm.score(X_train,y_train))\n",
        "print('test score:',svm.score(X_test,y_test))\n",
        "grad.fit(X_train,y_train)\n",
        "print('train score:',grad.score(X_train,y_train))\n",
        "print('test score:',grad.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uT0GGxxIZpu",
        "outputId": "ceca7691-9b61-4636-feba-eea9bfb68783"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score: 0.83645443196005\n",
            "test score: 0.8777777777777778\n",
            "train score: 0.8701622971285893\n",
            "test score: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columnas = train_df.drop(['PassengerId','Survived'],axis=1).columns.to_list()\n",
        "x_test = test_df[columnas]\n",
        "y_pred = svm.predict(x_test)\n",
        "ids = test_df['PassengerId']\n",
        "submission = pd.DataFrame({'PassengerId':ids,'Survived':y_pred})\n",
        "submission.to_csv('submission.csv',index=False)"
      ],
      "metadata": {
        "id": "XDQ5wPErIZnM"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}